{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c275e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a8bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Masking, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07356088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\KAVISH\\Downloads\\FidelFolio_df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "124992a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in ['Company', 'Year']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388c22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_lag1'] = df.groupby('Company')['Target 2'].shift(1)\n",
    "df['Target2_lag1'] = df['target_lag1'].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106c5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df.columns if col not in ['Company', 'Year', 'Target 2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f12a2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[feature_cols] = df[feature_cols].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cffb5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 3  # Increased sequence length\n",
    "MASK_VALUE = -999.\n",
    "BATCH_SIZE = 64  # Adjusted batch size\n",
    "EPOCHS = 30  # Increased epochs with early stopping\n",
    "INIT_LR = 0.0005  # Lower initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4222170",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[[col for col in feature_cols if col in df.columns]].values\n",
    "\n",
    "y_train = df['Target 2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4839cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "603/603 [==============================] - 3s 3ms/step - loss: 68096.9844 - mae: 138.2500 - val_loss: 226881.8906 - val_mae: 135.3683\n",
      "Epoch 2/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 42728.8828 - mae: 99.6695 - val_loss: 222529.7500 - val_mae: 114.9033\n",
      "Epoch 3/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 41956.1016 - mae: 96.7002 - val_loss: 227367.4219 - val_mae: 114.0913\n",
      "Epoch 4/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 41310.1289 - mae: 95.0134 - val_loss: 212728.5312 - val_mae: 120.1916\n",
      "Epoch 5/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 41431.0781 - mae: 94.3011 - val_loss: 219795.4062 - val_mae: 132.8773\n",
      "Epoch 6/50\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 41020.7070 - mae: 93.8000 - val_loss: 210254.7188 - val_mae: 110.7255\n",
      "Epoch 7/50\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 41872.4258 - mae: 93.0945 - val_loss: 232758.8750 - val_mae: 120.8591\n",
      "Epoch 8/50\n",
      "603/603 [==============================] - 4s 6ms/step - loss: 41459.5352 - mae: 93.3362 - val_loss: 241320.8906 - val_mae: 113.3166\n",
      "Epoch 9/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 40858.9258 - mae: 92.4386 - val_loss: 221278.3594 - val_mae: 109.3705\n",
      "Epoch 10/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 41366.7656 - mae: 93.0066 - val_loss: 246858.2500 - val_mae: 111.7121\n",
      "Epoch 11/50\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 41343.6836 - mae: 92.7947 - val_loss: 233379.6875 - val_mae: 108.9643\n",
      "Epoch 12/50\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 40879.5391 - mae: 92.2118 - val_loss: 225562.8750 - val_mae: 109.7709\n",
      "Epoch 13/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 41088.2852 - mae: 92.2576 - val_loss: 218100.3594 - val_mae: 109.7066\n",
      "Epoch 14/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 40998.4102 - mae: 92.0826 - val_loss: 237792.4062 - val_mae: 115.1839\n",
      "Epoch 15/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 40070.4492 - mae: 92.5904 - val_loss: 228410.0000 - val_mae: 113.6318\n",
      "Epoch 16/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 40591.5430 - mae: 91.8421 - val_loss: 239908.1094 - val_mae: 111.0991\n",
      "Epoch 17/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 40081.8984 - mae: 92.2083 - val_loss: 237787.6406 - val_mae: 109.4147\n",
      "Epoch 18/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 40265.8125 - mae: 92.1365 - val_loss: 230000.9844 - val_mae: 111.9978\n",
      "Epoch 19/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 39966.4961 - mae: 92.4097 - val_loss: 225290.4844 - val_mae: 110.2507\n",
      "Epoch 20/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 40394.6992 - mae: 92.2547 - val_loss: 231789.8281 - val_mae: 110.0834\n",
      "Epoch 21/50\n",
      "603/603 [==============================] - 2s 4ms/step - loss: 40117.6055 - mae: 92.3622 - val_loss: 228543.0156 - val_mae: 125.9675\n",
      "Epoch 22/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 39628.6914 - mae: 92.5113 - val_loss: 217067.9844 - val_mae: 115.3201\n",
      "Epoch 23/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39958.9766 - mae: 92.4139 - val_loss: 223381.1562 - val_mae: 112.6421\n",
      "Epoch 24/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39905.4883 - mae: 92.0882 - val_loss: 230756.2812 - val_mae: 110.0173\n",
      "Epoch 25/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39713.5703 - mae: 92.4381 - val_loss: 230414.1406 - val_mae: 109.4199\n",
      "Epoch 26/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39745.9219 - mae: 91.9422 - val_loss: 230959.2344 - val_mae: 108.1924\n",
      "Epoch 27/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39764.4453 - mae: 91.8706 - val_loss: 226630.4531 - val_mae: 114.4588\n",
      "Epoch 28/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39658.2227 - mae: 92.0501 - val_loss: 220556.6875 - val_mae: 110.4180\n",
      "Epoch 29/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39860.9648 - mae: 92.0488 - val_loss: 226699.4688 - val_mae: 115.2226\n",
      "Epoch 30/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39544.1367 - mae: 91.5518 - val_loss: 215199.8281 - val_mae: 120.7156\n",
      "Epoch 31/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39729.8477 - mae: 92.1230 - val_loss: 233831.6094 - val_mae: 108.5686\n",
      "Epoch 32/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39448.1289 - mae: 91.9469 - val_loss: 229115.7969 - val_mae: 111.2743\n",
      "Epoch 33/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39545.3281 - mae: 91.7731 - val_loss: 224129.1250 - val_mae: 111.8395\n",
      "Epoch 34/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39694.8125 - mae: 91.8118 - val_loss: 228389.9375 - val_mae: 109.8607\n",
      "Epoch 35/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39396.5469 - mae: 91.6542 - val_loss: 213862.7812 - val_mae: 113.3239\n",
      "Epoch 36/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39864.6914 - mae: 91.3863 - val_loss: 217642.1562 - val_mae: 118.8183\n",
      "Epoch 37/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39386.3203 - mae: 91.5328 - val_loss: 221325.3125 - val_mae: 107.9787\n",
      "Epoch 38/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39441.6797 - mae: 91.8594 - val_loss: 238601.3438 - val_mae: 107.6691\n",
      "Epoch 39/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39467.0742 - mae: 91.2665 - val_loss: 219723.0938 - val_mae: 114.2489\n",
      "Epoch 40/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39289.4336 - mae: 91.4649 - val_loss: 225541.2500 - val_mae: 107.8679\n",
      "Epoch 41/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 39339.4180 - mae: 91.1820 - val_loss: 230367.1406 - val_mae: 109.2343\n",
      "Epoch 42/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39188.5234 - mae: 91.3899 - val_loss: 230431.9062 - val_mae: 108.7800\n",
      "Epoch 43/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39268.3320 - mae: 91.3099 - val_loss: 227450.3125 - val_mae: 110.5767\n",
      "Epoch 44/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39298.2070 - mae: 90.7905 - val_loss: 227226.8125 - val_mae: 115.6171\n",
      "Epoch 45/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39304.7812 - mae: 91.3414 - val_loss: 229360.3750 - val_mae: 108.2537\n",
      "Epoch 46/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39352.9961 - mae: 91.1592 - val_loss: 229739.3750 - val_mae: 107.8484\n",
      "Epoch 47/50\n",
      "603/603 [==============================] - 1s 2ms/step - loss: 39163.9844 - mae: 90.0151 - val_loss: 223609.9219 - val_mae: 109.3490\n",
      "Epoch 48/50\n",
      "603/603 [==============================] - 4s 6ms/step - loss: 39025.2500 - mae: 90.3902 - val_loss: 233516.5625 - val_mae: 128.6954\n",
      "Epoch 49/50\n",
      "603/603 [==============================] - 5s 8ms/step - loss: 39255.1953 - mae: 90.6476 - val_loss: 232718.3125 - val_mae: 107.2476\n",
      "Epoch 50/50\n",
      "603/603 [==============================] - 3s 4ms/step - loss: 39064.2148 - mae: 90.1940 - val_loss: 231859.7500 - val_mae: 108.0238\n",
      "80/80 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df = df[df['Year'] < 2023].copy()\n",
    "test_df = df[df['Year'] > 2022].copy()\n",
    "\n",
    "\n",
    "#train_df = train_df.dropna(subset=[' Target 1 '])\n",
    "\n",
    "# Fill NaNs in features (you can also choose to drop or impute)\n",
    "X_columns = [col for col in train_df.columns if col not in ['Company', 'Year', 'Target 1','Target 2',  'target 3'] ]\n",
    "train_df[X_columns] = train_df[X_columns].fillna(-999)\n",
    "test_df[X_columns] = test_df[X_columns].fillna(-999)\n",
    "\n",
    "\n",
    "X_train = train_df[X_columns]\n",
    "y_train = train_df['Target 2'].values\n",
    "\n",
    "X_test = test_df[X_columns]\n",
    "\n",
    "# Build the MLP model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Regression output\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict for 2024\n",
    "predictions_2024 = model.predict(X_test)\n",
    "\n",
    "# Add predictions to test_df\n",
    "test_df['predicted_target2'] = predictions_2024\n",
    "\n",
    "# Save the predictions\n",
    "test_df[['Company', 'Year', 'predicted_target2']].to_csv(\"2024_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b032e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('test_data_processed2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
