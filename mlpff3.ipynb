{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42278fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bf9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Masking, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d09cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\KAVISH\\Downloads\\FidelFolio_df3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "477db899",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in ['Company', 'Year']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7689962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_lag1'] = df.groupby('Company')['Target 3'].shift(1)\n",
    "df['Target2_lag1'] = df['target_lag1'].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b15a6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df.columns if col not in ['Company', 'Year', 'Target 3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7495bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[feature_cols] = df[feature_cols].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2a47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 3  # Increased sequence length\n",
    "MASK_VALUE = -999.\n",
    "BATCH_SIZE = 64  # Adjusted batch size\n",
    "EPOCHS = 30  # Increased epochs with early stopping\n",
    "INIT_LR = 0.0005  # Lower initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4b8af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[[col for col in feature_cols if col in df.columns]].values\n",
    "\n",
    "y_train = df['Target 3'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa2d562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "560/560 [==============================] - 3s 3ms/step - loss: 62366.1133 - mae: 126.5677 - val_loss: 23139.1973 - val_mae: 76.5808\n",
      "Epoch 2/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 11438.0557 - mae: 59.1435 - val_loss: 34262.6094 - val_mae: 117.6678\n",
      "Epoch 3/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 9231.6270 - mae: 51.9699 - val_loss: 40194.9922 - val_mae: 116.9867\n",
      "Epoch 4/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 13473.2041 - mae: 63.6747 - val_loss: 8921.9697 - val_mae: 55.7522\n",
      "Epoch 5/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 13208.2646 - mae: 51.6576 - val_loss: 419970.9688 - val_mae: 69.7727\n",
      "Epoch 6/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 20461.2637 - mae: 60.9707 - val_loss: 5521.5669 - val_mae: 24.8253\n",
      "Epoch 7/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 5860.8042 - mae: 39.0972 - val_loss: 14331.4277 - val_mae: 37.8262\n",
      "Epoch 8/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 5643.4492 - mae: 33.2193 - val_loss: 24742.0547 - val_mae: 35.1537\n",
      "Epoch 9/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 12180.6748 - mae: 43.5429 - val_loss: 56713.7422 - val_mae: 53.6473\n",
      "Epoch 10/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 5709.7085 - mae: 32.1007 - val_loss: 123993.4922 - val_mae: 59.2769\n",
      "Epoch 11/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 4622.5415 - mae: 29.3143 - val_loss: 27032.5957 - val_mae: 40.1278\n",
      "Epoch 12/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 5659.5269 - mae: 31.9229 - val_loss: 76832.8672 - val_mae: 55.4937\n",
      "Epoch 13/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 4778.5288 - mae: 30.8349 - val_loss: 59806.7695 - val_mae: 46.2407\n",
      "Epoch 14/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 2712.4893 - mae: 21.2601 - val_loss: 84175.0078 - val_mae: 48.2933\n",
      "Epoch 15/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 9689.1709 - mae: 32.9300 - val_loss: 105183.7344 - val_mae: 59.5481\n",
      "Epoch 16/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 4072.9832 - mae: 24.2142 - val_loss: 75864.9609 - val_mae: 83.2412\n",
      "Epoch 17/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 7813.8223 - mae: 33.8265 - val_loss: 74087.9609 - val_mae: 48.3950\n",
      "Epoch 18/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 3193.9656 - mae: 22.6820 - val_loss: 109806.0234 - val_mae: 58.6351\n",
      "Epoch 19/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 2049.8401 - mae: 18.7864 - val_loss: 33724.8828 - val_mae: 45.7891\n",
      "Epoch 20/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 4115.3960 - mae: 24.4678 - val_loss: 44101.7031 - val_mae: 47.5472\n",
      "Epoch 21/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 3158.8342 - mae: 21.5163 - val_loss: 24071.3750 - val_mae: 33.3544\n",
      "Epoch 22/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 2154.6885 - mae: 21.1593 - val_loss: 68211.4688 - val_mae: 56.9368\n",
      "Epoch 23/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 2762.0142 - mae: 19.6469 - val_loss: 69386.2500 - val_mae: 60.8303\n",
      "Epoch 24/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 2040.1353 - mae: 18.7004 - val_loss: 59353.4805 - val_mae: 56.3219\n",
      "Epoch 25/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 3034.2673 - mae: 20.5460 - val_loss: 126299.8359 - val_mae: 63.4976\n",
      "Epoch 26/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 1607.2727 - mae: 14.9715 - val_loss: 85026.7812 - val_mae: 79.3541\n",
      "Epoch 27/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 6080.2144 - mae: 26.3896 - val_loss: 71770.8828 - val_mae: 62.2826\n",
      "Epoch 28/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 2688.4136 - mae: 18.8407 - val_loss: 58286.1445 - val_mae: 62.2683\n",
      "Epoch 29/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 1739.4766 - mae: 18.1521 - val_loss: 80037.6953 - val_mae: 63.7318\n",
      "Epoch 30/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 2603.6506 - mae: 18.7988 - val_loss: 136880.5312 - val_mae: 60.8857\n",
      "Epoch 31/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1905.9507 - mae: 15.0182 - val_loss: 84721.8672 - val_mae: 60.2206\n",
      "Epoch 32/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1229.2605 - mae: 13.8324 - val_loss: 103825.4609 - val_mae: 59.6175\n",
      "Epoch 33/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 1385.1102 - mae: 15.3193 - val_loss: 89151.5156 - val_mae: 55.0301\n",
      "Epoch 34/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 1758.4733 - mae: 14.5823 - val_loss: 103214.1328 - val_mae: 66.3933\n",
      "Epoch 35/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 2412.1777 - mae: 17.1144 - val_loss: 27081.8262 - val_mae: 64.9930\n",
      "Epoch 36/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 2752.7156 - mae: 20.6391 - val_loss: 129131.9219 - val_mae: 65.1527\n",
      "Epoch 37/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 2436.9890 - mae: 16.3295 - val_loss: 93720.6875 - val_mae: 63.5069\n",
      "Epoch 38/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 1150.1267 - mae: 12.4672 - val_loss: 93594.7734 - val_mae: 51.5853\n",
      "Epoch 39/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 1061.3630 - mae: 10.5231 - val_loss: 77969.9141 - val_mae: 56.2955\n",
      "Epoch 40/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 977.7258 - mae: 11.3677 - val_loss: 81468.2969 - val_mae: 55.1692\n",
      "Epoch 41/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1300.0934 - mae: 11.4172 - val_loss: 34069.9023 - val_mae: 44.5010\n",
      "Epoch 42/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 4133.1294 - mae: 20.0015 - val_loss: 175796.8594 - val_mae: 62.1828\n",
      "Epoch 43/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 1106.9220 - mae: 13.1988 - val_loss: 83693.6406 - val_mae: 56.8650\n",
      "Epoch 44/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 1965.1710 - mae: 14.4049 - val_loss: 79955.7344 - val_mae: 51.6220\n",
      "Epoch 45/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 1118.2762 - mae: 12.5476 - val_loss: 97355.2500 - val_mae: 66.8766\n",
      "Epoch 46/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 851.4416 - mae: 12.1391 - val_loss: 84513.4844 - val_mae: 57.2837\n",
      "Epoch 47/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 2432.3818 - mae: 16.5293 - val_loss: 119049.5234 - val_mae: 65.6579\n",
      "Epoch 48/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 804.2971 - mae: 12.1043 - val_loss: 96449.3125 - val_mae: 62.5944\n",
      "Epoch 49/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 709.5978 - mae: 9.7491 - val_loss: 95115.6562 - val_mae: 59.4256\n",
      "Epoch 50/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1281.3666 - mae: 10.6517 - val_loss: 108758.5781 - val_mae: 62.4153\n",
      "Epoch 51/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1582.6775 - mae: 15.4607 - val_loss: 82128.4609 - val_mae: 62.3396\n",
      "Epoch 52/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1150.7484 - mae: 12.6924 - val_loss: 81010.5859 - val_mae: 57.0296\n",
      "Epoch 53/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 512.8419 - mae: 9.1191 - val_loss: 87970.9609 - val_mae: 48.8364\n",
      "Epoch 54/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1863.8175 - mae: 13.4742 - val_loss: 52347.8711 - val_mae: 60.2094\n",
      "Epoch 55/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1970.8882 - mae: 16.3713 - val_loss: 95386.1797 - val_mae: 61.5833\n",
      "Epoch 56/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1033.3270 - mae: 11.4996 - val_loss: 101908.6719 - val_mae: 56.9883\n",
      "Epoch 57/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 906.5646 - mae: 10.8426 - val_loss: 95602.5156 - val_mae: 58.5567\n",
      "Epoch 58/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1761.7935 - mae: 14.8670 - val_loss: 107253.2422 - val_mae: 60.8482\n",
      "Epoch 59/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 697.2563 - mae: 10.4638 - val_loss: 88254.8359 - val_mae: 56.5413\n",
      "Epoch 60/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 744.5027 - mae: 11.3338 - val_loss: 91302.3906 - val_mae: 53.6758\n",
      "Epoch 61/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 307.5944 - mae: 6.6502 - val_loss: 45388.2227 - val_mae: 49.8400\n",
      "Epoch 62/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1059.6580 - mae: 11.0571 - val_loss: 98482.7188 - val_mae: 58.9641\n",
      "Epoch 63/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 858.6218 - mae: 11.5034 - val_loss: 111520.4766 - val_mae: 59.1647\n",
      "Epoch 64/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 967.8650 - mae: 12.3085 - val_loss: 112802.1562 - val_mae: 64.3738\n",
      "Epoch 65/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 692.9799 - mae: 9.7604 - val_loss: 5552.9194 - val_mae: 50.0162\n",
      "Epoch 66/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 3791.6223 - mae: 17.3627 - val_loss: 83153.6172 - val_mae: 53.1560\n",
      "Epoch 67/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 1160.3063 - mae: 13.5431 - val_loss: 92097.3281 - val_mae: 51.3134\n",
      "Epoch 68/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 475.1144 - mae: 7.6426 - val_loss: 92045.0469 - val_mae: 58.4126\n",
      "Epoch 69/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 705.6722 - mae: 9.5431 - val_loss: 107324.2578 - val_mae: 58.9823\n",
      "Epoch 70/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 352.7108 - mae: 7.9188 - val_loss: 66682.2422 - val_mae: 52.6325\n",
      "Epoch 71/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1733.6375 - mae: 12.8338 - val_loss: 45396.2930 - val_mae: 55.0133\n",
      "Epoch 72/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 1652.9003 - mae: 14.3188 - val_loss: 91870.8750 - val_mae: 55.9801\n",
      "Epoch 73/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 2919.6333 - mae: 14.4536 - val_loss: 216541.0000 - val_mae: 69.0672\n",
      "Epoch 74/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 1881.4009 - mae: 15.2086 - val_loss: 101374.1953 - val_mae: 55.4935\n",
      "Epoch 75/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 770.9193 - mae: 11.2240 - val_loss: 77177.3125 - val_mae: 58.5137\n",
      "Epoch 76/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 390.2550 - mae: 8.6378 - val_loss: 67788.0938 - val_mae: 58.9719\n",
      "Epoch 77/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 1078.7894 - mae: 11.6064 - val_loss: 88819.4766 - val_mae: 59.5260\n",
      "Epoch 78/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 554.6091 - mae: 9.9998 - val_loss: 101614.6406 - val_mae: 55.0600\n",
      "Epoch 79/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 442.5955 - mae: 10.0782 - val_loss: 83034.3750 - val_mae: 56.0093\n",
      "Epoch 80/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1468.3337 - mae: 13.2470 - val_loss: 94458.4531 - val_mae: 57.7787\n",
      "Epoch 81/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 972.5189 - mae: 12.4883 - val_loss: 68263.1094 - val_mae: 54.4036\n",
      "Epoch 82/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 621.0258 - mae: 11.0769 - val_loss: 81620.7891 - val_mae: 53.4532\n",
      "Epoch 83/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 228.1715 - mae: 7.0362 - val_loss: 134251.8750 - val_mae: 65.5385\n",
      "Epoch 84/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 725.1738 - mae: 11.6195 - val_loss: 74831.9219 - val_mae: 53.3653\n",
      "Epoch 85/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 710.4388 - mae: 9.6644 - val_loss: 66462.3203 - val_mae: 53.8586\n",
      "Epoch 86/100\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 486.5744 - mae: 9.8278 - val_loss: 86532.0547 - val_mae: 59.2989\n",
      "Epoch 87/100\n",
      "560/560 [==============================] - 1s 3ms/step - loss: 1529.8903 - mae: 15.6198 - val_loss: 88078.3594 - val_mae: 55.0651\n",
      "Epoch 88/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 830.1811 - mae: 11.6000 - val_loss: 89524.5781 - val_mae: 57.3038\n",
      "Epoch 89/100\n",
      "560/560 [==============================] - 2s 4ms/step - loss: 338.0945 - mae: 7.7656 - val_loss: 95536.8906 - val_mae: 53.5576\n",
      "Epoch 90/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 980.6822 - mae: 12.1068 - val_loss: 80654.8828 - val_mae: 54.1418\n",
      "Epoch 91/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 658.6732 - mae: 9.6271 - val_loss: 6958.4082 - val_mae: 38.8711\n",
      "Epoch 92/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 1314.1952 - mae: 13.9393 - val_loss: 107595.7891 - val_mae: 56.3112\n",
      "Epoch 93/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 606.7065 - mae: 10.7848 - val_loss: 71851.1953 - val_mae: 56.6663\n",
      "Epoch 94/100\n",
      "560/560 [==============================] - 2s 3ms/step - loss: 2539.9456 - mae: 11.8202 - val_loss: 101935.1484 - val_mae: 59.9983\n",
      "Epoch 95/100\n",
      "560/560 [==============================] - 2s 4ms/step - loss: 389.0521 - mae: 7.5354 - val_loss: 88933.4453 - val_mae: 54.5487\n",
      "Epoch 96/100\n",
      "560/560 [==============================] - 4s 7ms/step - loss: 626.1819 - mae: 9.3741 - val_loss: 121517.2578 - val_mae: 63.5711\n",
      "Epoch 97/100\n",
      "560/560 [==============================] - 3s 6ms/step - loss: 826.1649 - mae: 10.8246 - val_loss: 67483.4766 - val_mae: 53.9318\n",
      "Epoch 98/100\n",
      "560/560 [==============================] - 3s 6ms/step - loss: 1298.9379 - mae: 13.6870 - val_loss: 94864.6172 - val_mae: 54.5976\n",
      "Epoch 99/100\n",
      "560/560 [==============================] - 3s 5ms/step - loss: 515.3817 - mae: 9.0675 - val_loss: 98889.8828 - val_mae: 59.3115\n",
      "Epoch 100/100\n",
      "560/560 [==============================] - 4s 6ms/step - loss: 469.8589 - mae: 9.0843 - val_loss: 86345.4688 - val_mae: 55.4614\n",
      "118/118 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df = df[df['Year'] < 2022].copy()\n",
    "test_df = df[df['Year'] > 2021].copy()\n",
    "\n",
    "\n",
    "#train_df = train_df.dropna(subset=[' Target 1 '])\n",
    "\n",
    "# Fill NaNs in features (you can also choose to drop or impute)\n",
    "X_columns = [col for col in train_df.columns if col not in ['Company', 'Year', ' Target 1 ',' Target 2 ', ' Target 3 ']]\n",
    "train_df[X_columns] = train_df[X_columns].fillna(-999)\n",
    "test_df[X_columns] = test_df[X_columns].fillna(-999)\n",
    "\n",
    "\n",
    "X_train = train_df[X_columns]\n",
    "y_train = train_df['Target 3'].values\n",
    "\n",
    "X_test = test_df[X_columns]\n",
    "\n",
    "# Build the MLP model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Regression output\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Predict for 2024\n",
    "predictions_2024 = model.predict(X_test)\n",
    "\n",
    "# Add predictions to test_df\n",
    "test_df['predicted_target3'] = predictions_2024\n",
    "\n",
    "# Save the predictions\n",
    "test_df[['Company', 'Year', 'predicted_target3']].to_csv(\"2024_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f41d40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('C:/Users/KAVISH/Downloads/test_data_processed3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
